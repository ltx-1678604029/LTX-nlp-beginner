{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e44ef5a",
   "metadata": {},
   "source": [
    "实验目的：实现基于logistic/softmax regression的文本分类\n",
    "\n",
    "\n",
    "需要了解的知识点：\n",
    "\n",
    "1)文本特征表示：Bag-of-Word，N-gram\n",
    "\n",
    "2)分类器：logistic/softmax regression，损失函数、（随机）梯度下降、特征选择\n",
    "\n",
    "3)数据集：训练集/验证集/测试集的划分\n",
    "\n",
    "实验：\n",
    "\n",
    "分析不同的特征、损失函数、学习率对最终分类性能的影响\n",
    "\n",
    "shuffle 、batch、mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99e38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'C:\\Users\\16786\\Desktop\\复旦nlp上手教程\\task1\\sentiment-analysis-on-movie-reviews\\train.tsv',sep='\\t')\n",
    "test=pd.read_csv(r'C:\\Users\\16786\\Desktop\\复旦nlp上手教程\\task1\\sentiment-analysis-on-movie-reviews\\test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef53c6",
   "metadata": {},
   "source": [
    " 该数据集由制表符分隔的文件组成，其中包含来自烂番茄数据集的短语。出于基准测试的目的，保留了训练/测试拆分，但句子已从其原始顺序中洗牌。每个句子都被斯坦福解析器解析为许多短语。每个短语都有一个短语 Id。每个句子都有一个句子 Id。重复的短语（如短词/常用词）仅在数据中包含一次。\n",
    "\n",
    "train.tsv 包含短语及其关联的情绪标签。我们还提供了一个SectionId，以便您可以跟踪哪些短语属于单个句子。\n",
    "\n",
    "test.tsv 只包含短语。必须为每个短语分配一个情绪标签。\n",
    "\n",
    "情绪标签包括：\n",
    "\n",
    "0 - 负\n",
    "\n",
    "1 - 有点负\n",
    "\n",
    "2 - 中性\n",
    "\n",
    "3 - 有点正\n",
    "\n",
    "4 - 正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25bc06ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.info())\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008dcbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    66292 non-null  int64 \n",
      " 1   SentenceId  66292 non-null  int64 \n",
      " 2   Phrase      66292 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.info())\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec788c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.509945\n",
       "3    0.210989\n",
       "1    0.174760\n",
       "4    0.058990\n",
       "0    0.045316\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts()/train.Sentiment.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2f8ee",
   "metadata": {},
   "source": [
    "## 尝试手写Bag-of-Word模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b549e",
   "metadata": {},
   "source": [
    "列位置对应单词，列位置的数量大小对应该词在本句中出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd25f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bag_of_Word:\n",
    "    def __init__(self,do_lower_case=False):\n",
    "        self.do_lower_case=do_lower_case\n",
    "        self.feature_set=set()#利用set（集合）中元素不重复的特性\n",
    "    def fit_transform(self,data):\n",
    "        #首先把所有字母转化为小写字母\n",
    "        for sentence in data:\n",
    "            if self.do_lower_case:#此处一直为false，强制将所有字母转化为小写\n",
    "                sentence=sentence.lower()\n",
    "            words=sentence.split(' ')#把每句话拆成单词\n",
    "            for word in words:\n",
    "                self.feature_set.add(word)\n",
    "        feature_bow=np.zeros((len(data),len(self.feature_set)),dtype='uint8')\n",
    "        feature_dic=dict(zip(self.feature_set,range(len(self.feature_set))))#集合不能被索引，但是我们想用集合中单词的位置作为词表，转化为可索引的字典形势\n",
    "        for idx,sentence in enumerate(data):\n",
    "            if self.do_lower_case:\n",
    "                sentence=sentence.lower()\n",
    "            words=sentence.split(' ')\n",
    "            for word in words:\n",
    "                if word in self.feature_set:\n",
    "                    feature_bow[idx,feature_dic[word]]+=1\n",
    "        return feature_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506bb36",
   "metadata": {},
   "source": [
    "## 尝试手写N-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c0eaa",
   "metadata": {},
   "source": [
    "此处使用字典来实现“字典”的生成，也可改为上文BoW中的元组进行实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810997d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class N_Gram:\n",
    "    def __init__(self,ngram,do_lower_case=False):\n",
    "        self.ngram=ngram\n",
    "        self.feature_dict={}\n",
    "        self.do_lower_case=do_lower_case\n",
    "    def fit_transform(self,data):\n",
    "        for gram in self.ngram:\n",
    "            for sentence in data:\n",
    "                if self.do_lower_case:\n",
    "                    words=sentence.lower()\n",
    "                words=sentence.split(' ')\n",
    "                for i in range(len(words)-gram+1):#对n元特征，长度为L的句子能提取出L-N+1个N元特征\n",
    "                    feature=\"_\".join(words[i:(i+gram)])#生成一个n-gram词组,如i have经此处理得i_have,使其变成“一个词”,详见注\n",
    "                    if feature not in self.feature_dict:\n",
    "                        self.feature_dict[feature]=len(self.feature_dict)\n",
    "            n=len(data)#总句子数量\n",
    "            m=len(self.feature_dict)\n",
    "            ngram_feature = np.zeros((n, m),dtype='uint8')\n",
    "            for idx,sentence in enumerate(data):\n",
    "                if self.do_lower_case:\n",
    "                    words=sentence.lower()\n",
    "                words=sentence.split(' ')\n",
    "                for gram in self.ngram:\n",
    "                    for i in range(len(words)-gram+1):\n",
    "                        feature=\"_\".join(words[i:(i+gram)])\n",
    "                        if feature in self.feature_dict:\n",
    "                            ngram_feature[idx][self.feature_dict[feature]]=1\n",
    "        return ngram_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce9ba9",
   "metadata": {},
   "source": [
    "## 处理，划分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f77de",
   "metadata": {},
   "source": [
    "此处直接采用sklearn提供的相关工具，不再利用shuffel()自行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ddf404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b569517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train[\"Phrase\"].values, train[\"Sentiment\"].values\n",
    "#y = np.array(y).reshape((-1, 1))#把y变成“一列’\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c976b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bag_of_Word=Bag_of_Word()\n",
    "#N_Gram=N_Gram(ngram=(1, 2))\n",
    "\n",
    "X_BoW=Bag_of_Word.fit_transform(X)\n",
    "#X_NGram = N_Gram.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15da9848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 18227)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BoW.shape#,X_NGram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_BoW,X_test_BoW,y_train_BoW,y_test_BoW=train_test_split(X_BoW,y,test_size=0.2,random_state=42,stratify=y) \n",
    "#X_train_NGram, X_test_NGram, y_train_NGram, y_test_NGram=train_test_split(X_NGram, y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501bb456",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee9a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a01bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=LogisticRegression(solver='sag', multi_class='multinomial')\n",
    "model_1.fit(X_train_BoW,y_train_BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_1.predict(X_test_BoW)\n",
    "#评估\n",
    "print(np.mean(predict == y_test_BoW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#注 \n",
    "'''\n",
    "a=\"a b d d d v b e e\"\n",
    "b=a.split(' ')\n",
    "c=\"_\".join(b[0:2])\n",
    "c\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc1192",
   "metadata": {},
   "source": [
    "## 不知道为什么最后跑了半天跑不出来QAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd5a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
